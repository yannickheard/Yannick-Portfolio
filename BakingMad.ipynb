{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing of Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the baseline url I am using for the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = 'https://www.bakingmad.com'\n",
    "page = requests.get(baseurl)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to figure out the number of pages needed to scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getnumpages(section):\n",
    "    dessertsurl = 'https://www.bakingmad.com/recipes/' + section + '?pagesize=72&sort=Date&page=1'\n",
    "    dessertspage = requests.get(dessertsurl)\n",
    "    desserts = BeautifulSoup(dessertspage.content, 'html.parser')\n",
    "    total_results = desserts.find(class_ = 'listing-footer__results js-results').text.split(\" \")[2]\n",
    "    pages = math.ceil(float(total_results)/72)\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to pull the urls for the recipes into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrecipeurls(recipelist):\n",
    "    urllist = []\n",
    "    for i in recipelist:\n",
    "        link = i.find(class_ = 'summary__block-link')\n",
    "        actualurl = link['href']\n",
    "        urllist.append(actualurl)\n",
    "    return urllist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to pull ingredients from the recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients(recipesoup):\n",
    "    full_ingredient_list = []\n",
    "    ingredients = recipesoup.find_all(itemprop = \"recipeIngredient\")\n",
    "    \n",
    "    for things in ingredients:\n",
    "        listy=[]\n",
    "        item_dict = {}\n",
    "        spans = things.find_all('span')\n",
    "        \n",
    "        for span in spans:\n",
    "            listy.append(span.string)\n",
    "        item_dict['Amount'] = listy[0]\n",
    "        item_dict['Item'] = listy[2]\n",
    "        full_ingredient_list.append(item_dict)\n",
    "        \n",
    "    return full_ingredient_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to pull the method from the recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_method(recipesoup):\n",
    "    method = recipesoup.find_all(class_  = 'method__text')\n",
    "    stepnum = 1\n",
    "    recipesteps = {}\n",
    "    \n",
    "    for i in method:\n",
    "        step = i.text.strip('\\n')\n",
    "        recipesteps[stepnum] = step\n",
    "        stepnum += 1\n",
    "    total_steps = stepnum-1\n",
    "    \n",
    "    return(recipesteps, total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to pull the recipes from a certain section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recipes_from_section(urllist):\n",
    "    fullrecipe = {}\n",
    "    for page in urllist:\n",
    "        details = {}\n",
    "        recipepage = requests.get(baseurl + page)\n",
    "        recipesoup = BeautifulSoup(recipepage.content, 'html.parser')\n",
    "    \n",
    "        details['Ingredients'] = get_ingredients(recipesoup)\n",
    "        details['Steps'], details['Total Steps'] = get_method(recipesoup)\n",
    "        details[\"Time\"] = recipesoup.find(class_ = 'recipe-info__total-time').text.replace(\"TotalTime \", \"\").replace('\\n', '').replace('\\r', '').replace(' ', '')\n",
    "        details[\"Yield\"] = recipesoup.find(class_ = 'recipe-info__yield').text.replace('\\n', \" \")\n",
    "        details[\"Skill Level\"] = recipesoup.find(class_ = 'recipe-info__skill')['data-skill-level']\n",
    "        recipename = recipesoup.find(itemprop = 'name').string\n",
    "        fullrecipe[recipename] = details\n",
    "    return fullrecipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run through sections list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_url_list_section(section, numpagessection):\n",
    "    recipe_url_list = []\n",
    "    for num in range(1,numpagessection+1):\n",
    "        currentdesserturl ='https://www.bakingmad.com/recipes/' + section + '?pagesize=72&sort=Date&page=' + str(num)\n",
    "        currentdessertspage = requests.get(currentdesserturl)\n",
    "        currentdesserts = BeautifulSoup(currentdessertspage.content, 'html.parser')\n",
    "        recipelist = currentdesserts.find_all(class_='summary summary--recipe')\n",
    "        recipe_url_list.extend(getrecipeurls(recipelist))\n",
    "    \n",
    "    return recipe_url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing the sections I want scraped and having it scraped into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['desserts', 'bread-dough', 'cakes', 'confectionery', 'cookies-biscuits', 'cupcakes-muffins', 'ice-cream',\n",
    "           'icing-buttercream', 'jams-preserves', 'pancakes-batters', 'pastries', 'scones', 'sauces', 'traybakes']\n",
    "complete_baking_mad = {}\n",
    "for section in sections:\n",
    "    numpagessection = getnumpages(section)\n",
    "    full_urls_current_section = get_full_url_list_section(section, numpagessection)\n",
    "    all_recipes_current_section = recipes_from_section(full_urls_current_section)\n",
    "    complete_baking_mad[section] = all_recipes_current_section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the dictionary that has been formed from scraped form into a more usable dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wip = pd.DataFrame(complete_baking_mad['desserts']).transpose()\n",
    "df_wip['Section'] = 'desserts'\n",
    "for section in sections:\n",
    "    if section == 'desserts':\n",
    "        continue\n",
    "    else:\n",
    "        new_df = pd.DataFrame(complete_baking_mad[section]).transpose()\n",
    "        new_df['Section'] = section\n",
    "        df_wip = pd.concat([df_wip, new_df], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_wip.to_csv('C:/Users/yanni/Desktop/BakingMad.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
