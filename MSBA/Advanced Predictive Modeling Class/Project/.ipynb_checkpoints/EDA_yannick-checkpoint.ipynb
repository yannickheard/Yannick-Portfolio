{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data07=pd.read_csv(\"TEDS-D-2007-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data08=pd.read_csv(\"TEDS-D-2008-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data09=pd.read_csv(\"TEDS-D-2009-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data10=pd.read_csv(\"TEDS-D-2010-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data11=pd.read_csv(\"TEDS-D-2011-DS0001-data-excel.tsv\", sep='\\t')\n",
    "data12=pd.read_csv(\"TEDS-D-2012-DS0001-data-excel.csv\")\n",
    "data13=pd.read_csv(\"teds_d_2013.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data07 = data07.head(10000)\n",
    "data08 = data08.head(10000)\n",
    "data09 = data09.head(10000)\n",
    "data10 = data10.head(10000)\n",
    "data11 = data11.head(10000)\n",
    "data12 = data12.head(10000)\n",
    "data13 = data13.head(10000)\n",
    "frames=[data07,data08,data09,data10,data11,data12,data13]\n",
    "data=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "data.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from pandas import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">>> from sklearn import tree\n",
    ">>> X = \n",
    ">>> Y = \n",
    ">>> clf = tree.DecisionTreeClassifier()\n",
    ">>> clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.replace(-9, np.NaN , inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listed=set([])\n",
    "#Create Marriage Dummy Variables\n",
    "for elem in data['MARSTAT'].unique():\n",
    "    data['Marriage' + str(elem)] = data['MARSTAT'] == elem\n",
    "    listed.add('Marriage'+str(elem))\n",
    "#Create Area Dummy Variables\n",
    "for elem in data['STFIPS'].unique():\n",
    "     data['STFIPS' + str(elem)] = data['STFIPS'] == elem\n",
    "     listed.add('STFIPS'+str(elem))   \n",
    "#Create PsyProb Dummy Variables\n",
    "for elem in data['PSYPROB'].unique():\n",
    "     data['PSYPROB' + str(elem)] = data['PSYPROB'] == elem\n",
    "     listed.add('PSYPROB'+str(elem))           \n",
    "#Create Ethnicity Dummy Variables\n",
    "for elem in data['ETHNIC'].unique():\n",
    "     data['ETHNIC' + str(elem)] = data['ETHNIC'] == elem\n",
    "     listed.add('ETHNIC'+str(elem))                           \n",
    "#Create Preg Dummy Variables\n",
    "for elem in data['PREG'].unique():\n",
    "     data['PREG' + str(elem)] = data['PREG'] == elem\n",
    "     listed.add('PREG'+str(elem))   \n",
    "#Create Priminc Dummy Variables\n",
    "for elem in data['PRIMINC'].unique():\n",
    "     data['PRIMINC' + str(elem)] = data['PRIMINC'] == elem\n",
    "     listed.add('PRIMINC'+str(elem))   \n",
    "#Create PSource Dummy Variables\n",
    "for elem in data['PSOURCE'].unique():\n",
    "     data['PSOURCE' + str(elem)] = data['PSOURCE'] == elem\n",
    "     listed.add('PSOURCE'+str(elem))           \n",
    "#Create Race Dummy Variables\n",
    "for elem in data['RACE'].unique():\n",
    "     data['RACE' + str(elem)] = data['RACE'] == elem\n",
    "     listed.add('RACE'+str(elem))           \n",
    "#Create Route1 Dummy Variables\n",
    "for elem in data['ROUTE1'].unique():\n",
    "     data['ROUTE1' + str(elem)] = data['ROUTE1'] == elem\n",
    "     listed.add('ROUTE1'+str(elem))                   \n",
    "#Create Sub1 Dummy Variables\n",
    "for elem in data['SUB1'].unique():\n",
    "     data['SUB1' + str(elem)] = data['SUB1'] == elem\n",
    "     listed.add('SUB1'+str(elem))                     \n",
    "#Create Vet Dummy Variables\n",
    "for elem in data['VET'].unique():\n",
    "     data['VET' + str(elem)] = data['VET'] == elem\n",
    "     listed.add('VET'+str(elem))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.replace(to_replace=True, value='1', inplace=True)\n",
    "data.replace(to_replace=False, value='0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frst_dict = {1:11, 2:13, 3:16, 4:19, 5:23, 6:27, 7:32, 8:37, 9:42, 10:47, 11:52, 12:55}\n",
    "def frst_age(s):\n",
    "    if s in frst_dict.keys():\n",
    "        return frst_dict[s]\n",
    "    \n",
    "mar_dict={1:0, 2:1, 3:0, 4:0}\n",
    "def mar_change(s):\n",
    "    if s in mar_dict.keys():\n",
    "        return mar_dict[s]\n",
    "    \n",
    "freq_use_dict = {1:0, 2:2, 3:6, 4:18, 5:30}\n",
    "def freq_use(s):\n",
    "    if s in freq_use_dict.keys():\n",
    "        return freq_use_dict[s]\n",
    "\n",
    "age_dict={2:13, 3:16, 4:19, 5:23, 6:27, 7:32, 8:37, 9:42, 10:47, 11:52, 12:55}\n",
    "def group_age(s):\n",
    "    if s in age_dict.keys():\n",
    "        return age_dict[s]\n",
    "    \n",
    "gender_dict={1.0:0, 2.0:1}\n",
    "def gender_change(s):\n",
    "    if s in gender_dict.keys():\n",
    "        return gender_dict[s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['GENDER'] = data['GENDER'].map(gender_change)\n",
    "data['AGE']= data['AGE'].map(group_age)\n",
    "data['MARSTAT'] = data['MARSTAT'].map(mar_change)\n",
    "data['FRSTUSE1'] = data['FRSTUSE1'].map(frst_age)\n",
    "data['FREQ1'] = data['FREQ1'].map(freq_use)\n",
    "data['LenOfUse'] = data['AGE'] - data['FRSTUSE1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listed.add('AGE')\n",
    "listed_columns = []\n",
    "for i in listed:\n",
    "    listed_columns.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    num = i.find('nan')\n",
    "    if num != -1:\n",
    "        del data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove, race ethnic, educ, employ, ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= data['REASON']\n",
    "X= data\n",
    "del X['REASON']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-23d65f6cd3bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\yanni\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yanni\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\yanni\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 58\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
